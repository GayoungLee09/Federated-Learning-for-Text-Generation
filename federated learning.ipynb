{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tutorial, we start with a RNN that generates ASCII characters, and refine it via federated learning. We also show how the final weights can be fed back to the original Keras model, allowing easy evaluation and text generation using standard tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before begining, run the following to verify that environment is set up correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Error parsing requirements for absl-py: [Errno 2] No such file or directory: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\absl_py-0.13.0.dist-info\\\\METADATA'\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rapt (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade tensorflow-federated-nightly\n",
    "!pip install --quiet --upgrade nest-asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Hello, World!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# Test the TFF is working:\n",
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a model that was pre-trained following the TensorFlow tutorial Text generation using a RNN with eager execution.\n",
    "\n",
    "However, rather than training on The Complete Works of Shakespeare, we pre-trained the model on the text from the Charles Dickens' A Tale of Two Cities and A Christmas Carol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the vocab lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fixed vocabularly of ASCII chars that occur in the works of Shakespeare and Dickens:\n",
    "vocab = list('dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"&*.26:\\naeimquyAEIMQUY]!%)-159\\r')\n",
    "\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the pre-trained model and generate some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    # From https://www.tensorflow.org/tutorials/sequences/text_generation\n",
    "    num_generate = 200\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-models-public/dickens_rnn.batch1.kerasmodel\n",
      "16195584/16193984 [==============================] - 8s 0us/step\n",
      "What of TensorFlow Federated, you ask? The case of\n",
      "Monseigneur, in cruel separation and step, Darnay had side forty feet having happened to Miss Pross's pride,\n",
      "Some of the adjoining passages of Corways, presented by her head again.\n",
      "\n",
      "Lu\n"
     ]
    }
   ],
   "source": [
    "# Text generation requires a batch_size=1 model.\n",
    "keras_model_batch1 = load_model(batch_size=1)\n",
    "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Federated Shakespeare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tff.simulation.datasets package provides a variety of datasets that are split into \"clients\", where each client corresponds to a dataset on a particular device that might participate in federated learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-datasets-public/shakespeare.tar.bz2\n",
      "1851392/1848122 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = tff.simulation.datasets.shakespeare.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets provided by shakespeare.load_data() consist of a sequence of string Tensors, one for each line spoken by a particular character in a Shakespeare play. The client keys consist of the name of the play joined with the name of the character, so for example MUCH_ADO_ABOUT_NOTHING_OTHELLO corresponds to the lines for the character Othello in the play Much Ado About Nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Live regist'red upon our brazen tombs,\\nAnd then grace us in the disgrace of death;\\nWhen, spite of cormorant devouring Time,\\nTh' endeavour of this present breath may buy\\nThat honour which shall bate his scythe's keen edge,\\nAnd make us heirs of all eternity.\\nTherefore, brave conquerors- for so you are\\nThat war against your own affections\\nAnd the huge army of the world's desires-\\nOur late edict shall strongly stand in force:\\nNavarre shall be the wonder of the world;\\nOur court shall be a little Academe,\\nStill and contemplative in living art.\\nYou three, Berowne, Dumain, and Longaville,\\nHave sworn for three years' term to live with me\\nMy fellow-scholars, and to keep those statutes\\nThat are recorded in this schedule here.\\nYour oaths are pass'd; and now subscribe your names,\\nThat his own hand may strike his honour down\\nThat violates the smallest branch herein.\\nIf you are arm'd to do as sworn to do,\\nSubscribe to your deep oaths, and keep it too.\\nYour oath is pass'd to pass away from these.\", shape=(), dtype=string)\n",
      "tf.Tensor(b'this?\\nDid you hear the proclamation?', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Here the play is \"The Tragedy of King Lear\" and the character is \"King\".\n",
    "raw_example_dataset = train_data.create_tf_dataset_for_client('THE_TRAGEDY_OF_KING_LEAR_KING')\n",
    "# To allow for future extensions, each entry x is an OrderedDict with a single key 'snippets' which contains the text.\n",
    "for x in raw_example_dataset.take(2):\n",
    "    print(x['snippets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We now use tf.data.Dataset transformations to prepare this data for training the char RNN loaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input pre-processing parameters\n",
    "SEQ_LENGTH = 100\n",
    "BATCH_SIZE = 8\n",
    "BUFFER_SIZE = 100  # For dataset shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a lookup table to map string chars to indexes, using the vocab loaded above:\n",
    "table = tf.lookup.StaticHashTable(tf.lookup.KeyValueTensorInitializer(keys=vocab, values=tf.constant(list(range(len(vocab))),dtype=tf.int64)),default_value=0)\n",
    "\n",
    "def to_ids(x):\n",
    "    s = tf.reshape(x['snippets'], shape=[1])\n",
    "    chars = tf.strings.bytes_split(s).values\n",
    "    ids = table.lookup(chars)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def split_input_target(chunk):\n",
    "    input_text = tf.map_fn(lambda x: x[:-1], chunk)\n",
    "    target_text = tf.map_fn(lambda x: x[1:], chunk)\n",
    "    return (input_text, target_text)\n",
    "\n",
    "\n",
    "def preprocess(dataset):\n",
    "    return (dataset.map(to_ids).unbatch().batch(SEQ_LENGTH + 1, drop_remainder=True).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).map(split_input_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can preprocess our raw_example_dataset, and check the types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(8, 100), dtype=tf.int64, name=None), TensorSpec(shape=(8, 100), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "example_dataset = preprocess(raw_example_dataset)\n",
    "print(example_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model and test on the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenedCategoricalAccuracy(tf.keras.metrics.SparseCategoricalAccuracy):\n",
    "    \n",
    "\n",
    "    def __init__(self, name='accuracy', dtype=tf.float32):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, [-1, 1])\n",
    "        y_pred = tf.reshape(y_pred, [-1, len(vocab), 1])\n",
    "        return super().update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel\n",
      "16195584/16193984 [==============================] - 9s 1us/step\n",
      "Evaluating on an example Shakespeare character: 0.406750\n",
      "Expected accuracy for random guessing: 0.012\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on completely random data: 0.007\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8  # The training and eval batch size for the rest of this tutorial.\n",
    "keras_model = load_model(batch_size=BATCH_SIZE)\n",
    "keras_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[FlattenedCategoricalAccuracy()])\n",
    "\n",
    "# Confirm that loss is much lower on Shakespeare than on random data\n",
    "loss, accuracy = keras_model.evaluate(example_dataset.take(5), verbose=0)\n",
    "print('Evaluating on an example Shakespeare character: {a:3f}'.format(a=accuracy))\n",
    "\n",
    "# As a sanity check, we can construct some completely random data, where we expect the accuracy to be essentially random:\n",
    "random_guessed_accuracy = 1.0 / len(vocab)\n",
    "print('Expected accuracy for random guessing: {a:.3f}'.format(a=random_guessed_accuracy))\n",
    "random_indexes = np.random.randint(low=0, high=len(vocab), size=1 * BATCH_SIZE * (SEQ_LENGTH + 1))\n",
    "data = collections.OrderedDict(snippets=tf.constant(''.join(np.array(vocab)[random_indexes]), shape=[1, 1]))\n",
    "random_dataset = preprocess(tf.data.Dataset.from_tensor_slices(data))\n",
    "loss, accuracy = keras_model.evaluate(random_dataset, steps=10, verbose=0)\n",
    "print('Evaluating on completely random data: {a:.3f}'.format(a=accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model with Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the keras_model inside `create_tff_model()`, which TFF will call to produce a new copy of the model inside the graph that it will serialize.\n",
    "\n",
    "def create_tff_model():\n",
    "    # TFF uses an `input_spec` so it knows the types and shapes that your model expects.\n",
    "    input_spec = example_dataset.element_spec\n",
    "    keras_model_clone = tf.keras.models.clone_model(keras_model)\n",
    "    return tff.learning.from_keras_model(keras_model_clone,input_spec=input_spec,loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[FlattenedCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct a Federated Averaging iterative process, which we will use to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['gru_1/gru_cell/kernel:0', 'gru_1/gru_cell/recurrent_kernel:0', 'gru_1/gru_cell/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['gru_1/gru_cell/kernel:0', 'gru_1/gru_cell/recurrent_kernel:0', 'gru_1/gru_cell/bias:0'] when minimizing the loss.\n"
     ]
    }
   ],
   "source": [
    "# This command builds all the TensorFlow graphs and serializes them: \n",
    "fed_avg = tff.learning.build_federated_averaging_process(model_fn=create_tff_model,client_optimizer_fn=lambda: tf.keras.optimizers.SGD(lr=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the simplest possible loop, where we run federated averaging for one round on a single client on a single batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=4.402, accuracy=0.134\n"
     ]
    }
   ],
   "source": [
    "state = fed_avg.initialize()\n",
    "state, metrics = fed_avg.next(state, [example_dataset.take(5)])\n",
    "train_metrics = metrics['train']\n",
    "print('loss={l:.3f}, accuracy={a:.3f}'.format(l=train_metrics['loss'], a=train_metrics['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a slightly more interesting training and evaluation loop.\n",
    "\n",
    "So that this simulation still runs relatively quickly, we train on the same three clients each round, only considering two minibatches for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(client, source=train_data):\n",
    "    return preprocess(source.create_tf_dataset_for_client(client)).take(5)\n",
    "\n",
    "clients = ['ALL_S_WELL_THAT_ENDS_WELL_CELIA', 'MUCH_ADO_ABOUT_NOTHING_OTHELLO',]\n",
    "train_datasets = [data(client) for client in clients]\n",
    "\n",
    "# We concatenate the test datasets for evaluation with Keras by creating a dataset of Datasets, and then identity flat mapping across all the examples.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices([data(client, test_data) for client in clients]).flat_map(lambda x: x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial state of the model produced by fed_avg.initialize() is based on the random initializers for the Keras model, not the weights that were loaded, since clone_model() does not clone the weights. To start training from a pre-trained model, we set the model weights in the server state directly from the loaded model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 0\n",
      "\tEval: loss=3.042, accuracy=0.441\n",
      "\tTrain: loss=4.329, accuracy=0.090\n",
      "Round 1\n",
      "\tEval: loss=4.292, accuracy=0.156\n",
      "\tTrain: loss=4.184, accuracy=0.198\n",
      "Round 2\n",
      "\tEval: loss=4.169, accuracy=0.153\n",
      "\tTrain: loss=4.051, accuracy=0.204\n",
      "Round 3\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000226539F5B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000226539F5B88> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEval: loss=4.041, accuracy=0.194\n",
      "\tTrain: loss=3.920, accuracy=0.211\n",
      "Round 4\n",
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022653907DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022653907DC8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEval: loss=3.975, accuracy=0.164\n",
      "\tTrain: loss=3.810, accuracy=0.210\n",
      "Final evaluation\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022653BDDCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000022653BDDCA8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEval: loss=3.857, accuracy=0.172\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 5\n",
    "\n",
    "state = fed_avg.initialize()\n",
    "\n",
    "state = tff.learning.state_with_new_model_weights(state,trainable_weights=[v.numpy() for v in keras_model.trainable_weights],non_trainable_weights=[v.numpy() for v in keras_model.non_trainable_weights])\n",
    "\n",
    "\n",
    "def keras_evaluate(state, round_num):\n",
    "    keras_model = load_model(batch_size=BATCH_SIZE)\n",
    "    keras_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=[FlattenedCategoricalAccuracy()])\n",
    "    state.model.assign_weights_to(keras_model)\n",
    "    loss, accuracy = keras_model.evaluate(example_dataset, steps=2, verbose=0)\n",
    "    print('\\tEval: loss={l:.3f}, accuracy={a:.3f}'.format(l=loss, a=accuracy))\n",
    "\n",
    "\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "    print('Round {r}'.format(r=round_num))\n",
    "    keras_evaluate(state, round_num)\n",
    "    state, metrics = fed_avg.next(state, train_datasets)\n",
    "    train_metrics = metrics['train']\n",
    "    print('\\tTrain: loss={l:.3f}, accuracy={a:.3f}'.format(l=train_metrics['loss'], a=train_metrics['accuracy']))\n",
    "\n",
    "print('Final evaluation')\n",
    "keras_evaluate(state, NUM_ROUNDS + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the default changes, we haven't done enough training to make a big difference, but if you train longer on more Shakespeare data, you should see a difference in the style of the text generated with the updated model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What of TensorFlow Federated, you ask? Say whend\n",
      "her father took him if I could hope, five fure\n",
      "and drank words of very day, and a barrier be marrier--said:\n",
      "\n",
      "\"That's all the sight of me, and myself, Mr. Carton?\"\n",
      "\n",
      "And smooth in fast u\n"
     ]
    }
   ],
   "source": [
    "# Set our newly trained weights back in the originally created model.\n",
    "keras_model_batch1.set_weights([v.numpy() for v in keras_model.weights])\n",
    "\n",
    "print(generate_text(keras_model_batch1, 'What of TensorFlow Federated, you ask? '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
